{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd50eafa-e177-4f79-9c29-a060c29718b4",
   "metadata": {},
   "source": [
    "# Vector Database (Bancos de Dados vetoriais) e Embeddings Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773aa23-a040-43cf-9c82-1e2de806f519",
   "metadata": {},
   "source": [
    "## Introdução Vector Database : \n",
    "\n",
    "Podemos definir Banco de Dados Veorial como uma solução de gerenciamento de dados projetada para otimizar a recuperação e o armazenamento de informações em formato de vetores.\n",
    "Essa abordagem utiliza algoritmos específicos para transformar os dados em um conjunto de números (vetores), que são representados em um espaço vetorial.\n",
    "Essa solução é muito importante para aplicações de Machine Learning e Inteligência Artificial, pois permite encontrar itens semelhantes com base na proximidade vetorial, viabilizando funcionalidades como busca semântica, sistemas de recomendação e análise de padrões de forma eficiente e escalável."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f62ae9c-1bc9-413c-929f-5979a3e8c373",
   "metadata": {},
   "source": [
    "## Weaviate:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4784bd4-cb06-49d1-a06c-ef9974d74a0c",
   "metadata": {},
   "source": [
    "Existem diversos tipo de soluções de banco de dados vetoriais disponiveis no mercado, mas para nossos testes, utilizaremos o Weaviate(https://weaviate.io/), pois, além de ser open-source, ele oferece excelente suporte para buscas semânticas e dados estruturados, além de integração com modelos de embeddings populares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f7b42-ce4a-4fa6-832b-e086e49ceabb",
   "metadata": {},
   "source": [
    "## O que são Modelos de Embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06601054-3fa0-4b92-9eb2-61792295a35e",
   "metadata": {},
   "source": [
    "Bascimente os Embeddings são representações vetoriais de dados que capturam seus significados ou características de forma numérica em um espaço de alta dimensão. \n",
    "\n",
    "É um conceito amplamente utilizados em Machine Learning, especialmente em tarefas de processamento de linguagem natural (PLN) e visão computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c9fab-9e30-425c-adb4-b641dbbb001f",
   "metadata": {},
   "source": [
    "### **Objetivos:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2750e-2fbc-4a03-bf0f-0858f7fc9ffa",
   "metadata": {},
   "source": [
    "Como dito anteriormente, o principal objetivo dos modelos de embeddings é representar dados textuais, visuais ou numéricos em um formato numérico, preservando suas relações semânticas. Em outras palavras, isso significa que a representação vetorial das palavras \"cachorro\" e \"gato\" será semanticamente próxima, enquanto \"cachorro\" e \"carro\" estarão mais distantes no espaço vetorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33347780-e1d0-4b58-a885-7980b2f56cb2",
   "metadata": {},
   "source": [
    "### Exemplos de Modelos de Embeddings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66cf187-d0c8-4211-ae8c-3c72ade0441c",
   "metadata": {},
   "source": [
    "**Modelos populares de embeddings:**\n",
    "- **Word2Vec:** Gera embeddings estáticos para palavras com base em coocorrência no texto.\n",
    "- **GloVe:** Similar ao Word2Vec, mas utiliza estatísticas globais de um corpus.\n",
    "- **BERT:** Modelo contextualizado que gera embeddings específicos para cada palavra em uma sentença, considerando o contexto.\n",
    "- **CLIP:** Utilizado para embeddings de texto e imagens, projetados no mesmo espaço vetorial.\n",
    "- **Sentence Transformers (SBERT):** Ideal para embeddings de frases e documentos.\n",
    "\n",
    "Cada modelo é projetado para atender a diferentes tipos de tarefas. Escolha o mais adequado com base no problema a ser resolvido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b26a15-73d4-44f3-9f1a-477cd9c18425",
   "metadata": {},
   "source": [
    "### Geração de Embeddings na Prática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa409964-41ae-47be-8786-f557ddacebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964b8323-48b8-48b3-b604-be32b1be5e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d46f87561f6474a821f2fe560493784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dtiDigital\\Documents\\Codice Juridico\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dtiDigital\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b154d2cf0484e56ad870743aedd85f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994a83870d644af38fe5a74da0347a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54cd2fd94624b40846e6f2eb65074ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5ddc2c8b8841d8aa42ad7a0809822a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9270fc82cdd48fc959e7a2f0556d476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e789ff0b21f490c9ec2369b3f580578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee25b5985d1640798c66b50ff4222b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cd99ce17814c4d80ddb38f2274d274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a330247c234b1aaa1e52c21abf7af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9818791b465a4cdfab275ee1b9937d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carregando o Modelo\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a26498aa-07a5-4987-833f-426b86836df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [\n",
    "    \"O cachorro está no parque.\",\n",
    "    \"O gato subiu na árvore.\",\n",
    "    \"OS Carros são meios de transporte.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1eda873-6fcd-4efc-812c-855d13e2568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando embeddings\n",
    "embeddings = model.encode(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "232e25d2-949c-4a0b-aa33-18119b37e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: O cachorro está no parque.\n",
      "Embedding: [-0.03486934  0.00535641 -0.02055818 -0.01926387 -0.08245736]... (dimensão: 384)\n",
      "\n",
      "Frase: O gato subiu na árvore.\n",
      "Embedding: [-0.09742771  0.05417777 -0.06127026  0.02175123 -0.07582309]... (dimensão: 384)\n",
      "\n",
      "Frase: Carros são meios de transporte.\n",
      "Embedding: [ 0.01851568  0.03419538 -0.00255625  0.05014872 -0.0176652 ]... (dimensão: 384)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrando resultados\n",
    "for i, frase in enumerate(frases):\n",
    "    print(f\"Frase: {frase}\")\n",
    "    print(f\"Embedding: {embeddings[i][:5]}... (dimensão: {len(embeddings[i])})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4268c4c-a532-4804-8597-5e5633043071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd50eafa-e177-4f79-9c29-a060c29718b4",
   "metadata": {},
   "source": [
    "# Vector Database (Bancos de Dados vetoriais) e Embeddings Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773aa23-a040-43cf-9c82-1e2de806f519",
   "metadata": {},
   "source": [
    "## Introdução Vector Database : \n",
    "\n",
    "Podemos definir Banco de Dados Veorial como uma solução de gerenciamento de dados projetada para otimizar a recuperação e o armazenamento de informações em formato de vetores.\n",
    "Essa abordagem utiliza algoritmos específicos para transformar os dados em um conjunto de números (vetores), que são representados em um espaço vetorial.\n",
    "Essa solução é muito importante para aplicações de Machine Learning e Inteligência Artificial, pois permite encontrar itens semelhantes com base na proximidade vetorial, viabilizando funcionalidades como busca semântica, sistemas de recomendação e análise de padrões de forma eficiente e escalável."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f62ae9c-1bc9-413c-929f-5979a3e8c373",
   "metadata": {},
   "source": [
    "## Weaviate:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4784bd4-cb06-49d1-a06c-ef9974d74a0c",
   "metadata": {},
   "source": [
    "Existem diversos tipo de soluções de banco de dados vetoriais disponiveis no mercado, mas para nossos testes, utilizaremos o Weaviate(https://weaviate.io/), pois, além de ser open-source, ele oferece excelente suporte para buscas semânticas e dados estruturados, além de integração com modelos de embeddings populares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f7b42-ce4a-4fa6-832b-e086e49ceabb",
   "metadata": {},
   "source": [
    "## O que são Modelos de Embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06601054-3fa0-4b92-9eb2-61792295a35e",
   "metadata": {},
   "source": [
    "Bascimente os Embeddings são representações vetoriais de dados que capturam seus significados ou características de forma numérica em um espaço de alta dimensão. \n",
    "\n",
    "É um conceito amplamente utilizados em Machine Learning, especialmente em tarefas de processamento de linguagem natural (PLN) e visão computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c9fab-9e30-425c-adb4-b641dbbb001f",
   "metadata": {},
   "source": [
    "### **Objetivos:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2750e-2fbc-4a03-bf0f-0858f7fc9ffa",
   "metadata": {},
   "source": [
    "Como dito anteriormente, o principal objetivo dos modelos de embeddings é representar dados textuais, visuais ou numéricos em um formato numérico, preservando suas relações semânticas. Em outras palavras, isso significa que a representação vetorial das palavras \"cachorro\" e \"gato\" será semanticamente próxima, enquanto \"cachorro\" e \"carro\" estarão mais distantes no espaço vetorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33347780-e1d0-4b58-a885-7980b2f56cb2",
   "metadata": {},
   "source": [
    "### Exemplos de Modelos de Embeddings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66cf187-d0c8-4211-ae8c-3c72ade0441c",
   "metadata": {},
   "source": [
    "**Modelos populares de embeddings:**\n",
    "- **Word2Vec:** Gera embeddings estáticos para palavras com base em coocorrência no texto.\n",
    "- **GloVe:** Similar ao Word2Vec, mas utiliza estatísticas globais de um corpus.\n",
    "- **BERT:** Modelo contextualizado que gera embeddings específicos para cada palavra em uma sentença, considerando o contexto.\n",
    "- **CLIP:** Utilizado para embeddings de texto e imagens, projetados no mesmo espaço vetorial.\n",
    "- **Sentence Transformers (SBERT):** Ideal para embeddings de frases e documentos.\n",
    "\n",
    "Cada modelo é projetado para atender a diferentes tipos de tarefas. Escolha o mais adequado com base no problema a ser resolvido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b26a15-73d4-44f3-9f1a-477cd9c18425",
   "metadata": {},
   "source": [
    "### Geração de Embeddings na Prática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686148d-57cb-46f9-bf31-f8b7eaef188d",
   "metadata": {},
   "source": [
    "Nesta sessão, vamos explorar modelos de embeddings e realizar análises para entender melhor o conceito de análise semântica e contextual entre diferentes tipos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa409964-41ae-47be-8786-f557ddacebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964b8323-48b8-48b3-b604-be32b1be5e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d46f87561f6474a821f2fe560493784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dtiDigital\\Documents\\Codice Juridico\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dtiDigital\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b154d2cf0484e56ad870743aedd85f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994a83870d644af38fe5a74da0347a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54cd2fd94624b40846e6f2eb65074ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5ddc2c8b8841d8aa42ad7a0809822a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9270fc82cdd48fc959e7a2f0556d476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e789ff0b21f490c9ec2369b3f580578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee25b5985d1640798c66b50ff4222b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cd99ce17814c4d80ddb38f2274d274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a330247c234b1aaa1e52c21abf7af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9818791b465a4cdfab275ee1b9937d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carregando o Modelo\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a26498aa-07a5-4987-833f-426b86836df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das frases que usaremos como exemplo\n",
    "frases = [\n",
    "    \"O cachorro está no parque.\",\n",
    "    \"O gato subiu na árvore.\",\n",
    "    \"Carros são meios de transporte.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f1eda873-6fcd-4efc-812c-855d13e2568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando embeddings\n",
    "embeddings = model.encode(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "232e25d2-949c-4a0b-aa33-18119b37e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: O cachorro está no parque.\n",
      "Embedding: [-0.03486934  0.00535641 -0.02055818 -0.01926387 -0.08245736]... (dimensão: 384)\n",
      "\n",
      "Frase: O gato subiu na árvore.\n",
      "Embedding: [-0.09742771  0.05417777 -0.06127026  0.02175123 -0.07582309]... (dimensão: 384)\n",
      "\n",
      "Frase: Carros são meios de transporte.\n",
      "Embedding: [ 0.01851568  0.03419538 -0.00255625  0.05014872 -0.0176652 ]... (dimensão: 384)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrando resultados\n",
    "for i, frase in enumerate(frases):\n",
    "    print(f\"Frase: {frase}\")\n",
    "    print(f\"Embedding: {embeddings[i][:5]}... (dimensão: {len(embeddings[i])})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aefbfb3-7825-4aa4-8992-2304936d8458",
   "metadata": {},
   "source": [
    "Parece aleatório, né? Vamos entender melhor o que esses números \"aleatórios\" representam.\n",
    "Acredito que o ponto mais importe para entender é que o vetor deve ser analisado como um todo, o que quero dizer que apensar do conter 5 números e as frases conterem 5 palavras, esses valores não representam diretamente o significado de palavras específicas da frase. Em outras palavras, não podemos olhar para um único número no vetor e dizer que ele corresponde a uma palavra ou ideia.\n",
    "\n",
    "Portanto, não podemos interpretar diretamente que palavras como \"gato\" e \"cachorro\" são semelhantes só porque um valor específico nos embeddings é próximo. O vetor completo (todos as 384 dimensões) deve ser considerado para avaliar semelhança.\n",
    "\n",
    "O interessante de entendermos esse conceito é que começamos a entender como os famosos LLMs funcionam, mas o que isso quer dizer? Pense no seguinte exemplo: em português, a palavra \"cachorro\" pode ter vários significados. Ela pode se referir ao animal, mas também pode ser usada de forma figurada para descrever alguém bravo, alguém que não presta, ou até em expressões regionais. Agora, imagine que o computador não raciocina e não entende palavras ou significados como nós, humanos. Para ele, tudo se resume a números. Então, para que ele consiga distinguir entre o \"cachorro\" animal e o \"cachorro\" de uma expressão figurada, precisamos fornecer um modelo matemático que capture essas nuances. É aqui que os embeddings entram: eles traduzem as frases em vetores numéricos que representam o contexto e o significado subjacente.\n",
    "\n",
    "Abaixo, realizaremos o embedding de algumas frases para compreender melhor as diferenças contextuais e semânticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8a05dc12-7892-4358-8618-72c2f57c020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das frases que usaremos como exemplo\n",
    "frases = [\n",
    "    \"O cachorro está no quintal.\", \n",
    "    \"Ele é um cachorro bravo, ninguém consegue conversar com ele.\",  \n",
    "    \"Aquele homem é um cachorro, traiu a namorada de novo.\", \n",
    "    \"O cachorro está no quintal brincando com os brinquedos dele.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4e95e906-c9d6-4bf2-888f-4892ffe40232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando embeddings\n",
    "embeddings = model.encode(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "30064d84-1e20-4d04-87bd-a6ef6f8a64c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade entre frases 1 e 2: 0.5939\n",
      "Similaridade entre frases 1 e 3: 0.5420\n",
      "Similaridade entre frases 2 e 3: 0.5886\n",
      "Similaridade entre frases 1 e 4: 0.7778\n"
     ]
    }
   ],
   "source": [
    "# Calculando similaridades\n",
    "similaridade_1_2 = util.cos_sim(embeddings[0], embeddings[1])\n",
    "similaridade_1_3 = util.cos_sim(embeddings[0], embeddings[2])\n",
    "similaridade_2_3 = util.cos_sim(embeddings[1], embeddings[2])\n",
    "similaridade_1_4 = util.cos_sim(embeddings[0], embeddings[3])\n",
    "\n",
    "# Mostrando resultados\n",
    "print(f\"Similaridade entre frases 1 e 2: {similaridade_1_2.item():.4f}\")\n",
    "print(f\"Similaridade entre frases 1 e 3: {similaridade_1_3.item():.4f}\")\n",
    "print(f\"Similaridade entre frases 2 e 3: {similaridade_2_3.item():.4f}\")\n",
    "print(f\"Similaridade entre frases 1 e 4: {similaridade_1_4.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b3fe7-edde-42ae-919d-d514ceda1085",
   "metadata": {},
   "source": [
    "Depois de executar essa celulas do notebook acredito que fique mais facil entender um pouco sobre o que comentei a cima, mas antes é importante resultar o significado de 2 palavras e suas diferenças: \n",
    "\n",
    "- **Semantica:** Semântica é o estudo do significado das palavras, frases e sentenças em um idioma. Refere-se à relação entre os símbolos linguísticos (como palavras e frases) e os conceitos ou significados que eles representam.\n",
    "- **Contexto:** contexto refere-se ao conjunto de informações ou circunstâncias que rodeiam um evento, situação, ou palavra, e que ajudam a interpretar o seu significado de forma adequada. No caso de linguagens, o contexto pode incluir palavras adjacentes, o tópico da conversa ou mesmo a intenção do autor. Exemplo: A palavra \"banco\" pode significar uma instituição financeira ou um objeto para sentar, dependendo do contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4182bfa9-ceb1-47f9-8f7d-2d8c9231fc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
